{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_yWjmlg44yb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from numpy import array\n",
    "from matplotlib.pyplot import ion\n",
    "from scipy.stats import norm, multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OEy5O4i5FGC"
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "#Load byte data from file\n",
    "  with open(file, 'rb') as f:\n",
    "    data = pickle.load(f, encoding='latin-1')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lbcdvM0P5Mht"
   },
   "outputs": [],
   "source": [
    " \n",
    "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = '█'):\n",
    "  percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
    "  filledLength = int(length * iteration // total)\n",
    "  bar = fill * filledLength + '-' * (length - filledLength)\n",
    "  print('\\r%s |%s| %s%% %s' % (prefix, bar, percent, suffix), end = '\\r')\n",
    "# Print New Line on Complete\n",
    "  if iteration == total: \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-HQpXdd5WdN"
   },
   "outputs": [],
   "source": [
    "def load_cifar10_data(data_dir):\n",
    "# Return train_data, train_labels, test_data, test_labels\n",
    "# The shape of data is 32 x 32 x3\n",
    "  train_data = None\n",
    "  train_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HMWYrEs5jGO"
   },
   "outputs": [],
   "source": [
    "  def load_cifar10_data(data_dir):\n",
    "\n",
    "  # Return train_data, train_labels, test_data, test_labels\n",
    "  # The shape of data is 32 x 32 x3\n",
    "    train_data = None\n",
    "    train_labels = []\n",
    "    for i in range(1, 6):\n",
    "        data_dic = unpickle(data_dir + \"/data_batch_{}\".format(i))\n",
    "        if i == 1:\n",
    "            train_data = data_dic['data']\n",
    "        else:\n",
    "            train_data = np.vstack((train_data, data_dic['data']))\n",
    "            train_labels += data_dic['labels']\n",
    "\n",
    "            test_data_dic = unpickle(data_dir + \"/test_batch\")\n",
    "            test_data = test_data_dic['data']\n",
    "            test_labels = test_data_dic['labels']\n",
    "\n",
    "            train_labels = np.array(train_labels)\n",
    "            test_labels = np.array(test_labels)\n",
    "\n",
    "            return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odICkJU2CMOJ"
   },
   "outputs": [],
   "source": [
    "# Computes the classification accuracy for predicted labels _pred_ as compared to the ground truth labels _gt_\n",
    "def cifar_10_evaluate(pred,gt):\n",
    "  indexes = 0\n",
    "  for i, val in enumerate(pred):\n",
    "    if pred[i] == gt[i]:\n",
    "      indexes = indexes+1\n",
    "# Counting number of predicted labels, which are same as true labels (how many)\n",
    "  l = indexes\n",
    "  p = l/len(gt)*100\n",
    "  print('The classification accuracy is '+  str(p) + \"%\")\n",
    "  return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asHehhzoC00W"
   },
   "outputs": [],
   "source": [
    "def cifar_10_rand(x):\n",
    "  pred = []\n",
    "  for i in range(len(x)):\n",
    "# Here we generate random number and append it to pred\n",
    "    numb = np.int32(random.randint(0,9))\n",
    "    pred.append(numb)\n",
    "  x = x.tolist()\n",
    "  cifar_10_evaluate(pred, x)\n",
    "  print ('< -- for random')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJNSQKHnC38i"
   },
   "outputs": [],
   "source": [
    "def cifar_show_guess(img, lbl_pred, lbl_real):\n",
    "# In order to check where the data shows an image correctly\n",
    "  ion()\n",
    "  plt.imshow(img)\n",
    "  plt.title(label_names[lbl_real] + ' - real; predicted: ' + label_names[lbl_pred])\n",
    "  plt.show()\n",
    "  plt.pause(2)\n",
    "  plt.close()\n",
    "\n",
    "def cifar_10_features(x):\n",
    "  result = []\n",
    "  for item in x:\n",
    "    r = item[0:1024]\n",
    "    g = item[1024:2048]\n",
    "    b = item[2048:3072]\n",
    "    means = [np.mean(r), np.mean(g), np.mean(b)]\n",
    "    result.append(means)\n",
    "  return np.asarray(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ruhDC38DD06"
   },
   "outputs": [],
   "source": [
    "def cifar_10_bayes_learn(f, labels):\n",
    "  # для каждого айтема определяем лейбл, затем считаем усредненные параметры для каждого класса\n",
    "  # для начала нужно выделить классы\n",
    "  # сначала определяем лейбл изображения. затем сортируем. затем считаем параметры для каждого класса по отдельности.\n",
    "  class_nums = list(range(0, 10))\n",
    "  data_l = len(f)\n",
    "  sorted = []\n",
    "  data = []\n",
    "  means = []\n",
    "  variances = []\n",
    "  ps = []\n",
    "  labels = labels.tolist()\n",
    "  for lbl in class_nums:\n",
    "    list_of_same_lbl = []\n",
    "    for index, item in enumerate(f):\n",
    "      if (labels[index] == lbl):\n",
    "        list_of_same_lbl.append(item)\n",
    "    sorted.append(list_of_same_lbl)\n",
    "\n",
    "  for item in sorted:\n",
    "    item = np.asarray(item)\n",
    "    data.append([np.mean(item, axis = 0, dtype=np.float64), np.std(item, axis = 0, dtype=np.float64), len(item)/data_l])\n",
    "    means.append(np.mean(item, axis = 0, dtype=np.float64))\n",
    "    variances.append(np.std(item, axis = 0, dtype=np.float64))\n",
    "    ps.append(len(item)/data_l)\n",
    "  return data, means, variances, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7Ra-3bsFET8"
   },
   "outputs": [],
   "source": [
    "def cifar_10_multivariative_learn(f, labels):\n",
    "  # для каждого айтема определяем лейбл, затем считаем усредненные параметры для каждого класса\n",
    "  # для начала нужно выделить классы\n",
    "  # сначала определяем лейбл изображения. затем сортируем. затем считаем параметры для каждого класса по отдельности.\n",
    "  class_nums = list(range(0, 10))\n",
    "  data_l = len(f)\n",
    "  sorted = []\n",
    "  data = []\n",
    "  means = []\n",
    "  covariances = []\n",
    "  ps = []\n",
    "  labels = labels.tolist()\n",
    "  for lbl in class_nums:\n",
    "    list_of_same_lbl = []\n",
    "    for index, item in enumerate(f):\n",
    "      if (labels[index] == lbl):\n",
    "        list_of_same_lbl.append(item)\n",
    "    sorted.append(list_of_same_lbl)\n",
    "\n",
    "  for item in sorted:\n",
    "    item = np.asarray(item)\n",
    "    means.append(np.mean(item, axis = 0, dtype=np.float64))\n",
    "    covariances.append(np.cov(item, rowvar = 0))\n",
    "    ps.append(len(item)/data_l)\n",
    "  return means, covariances, ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJDxiFVHFJ88"
   },
   "outputs": [],
   "source": [
    "def cifar_10_bayes_classify(f_s,mu,sigma,p,test_labels):\n",
    "  pred = []\n",
    "  i = 0\n",
    "  l = len(f_s)\n",
    "  print(l)\n",
    "  printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "  class_nums = list(range(0, 10))\n",
    "  for f in f_s:\n",
    "    printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "    probabilities = []\n",
    "    for lbl in class_nums:\n",
    "      prob = norm.pdf(f[0], mu[lbl][0], sigma[lbl][0]) * norm.pdf(f[1], mu[lbl][1], sigma[lbl][1]) *  norm.pdf(f[2], mu[lbl][2], sigma[lbl][2]) * p[lbl]   \n",
    "      probabilities.append(prob)\n",
    "    maxin,indx = max((probabilities[i],i) for i in range(len(probabilities))) \n",
    "    pred.append(indx)\n",
    "    i = i+1\n",
    "    \n",
    "  cifar_10_evaluate(pred,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iEs5kJ70FQDL"
   },
   "outputs": [],
   "source": [
    "def cifar_10_multivariative_classify(f_s,mu,cov,p,test_labels):\n",
    "  pred = []\n",
    "  i = 0\n",
    "  l = len(f_s)\n",
    "  print(l)\n",
    "  printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "  class_nums = list(range(0, 10))\n",
    "  for f in f_s:\n",
    "    printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete')\n",
    "    probabilities = []\n",
    "    for lbl in class_nums:\n",
    "      prob = multivariate_normal.pdf(f, mu[lbl], cov[lbl]) * p[lbl]   \n",
    "      probabilities.append(prob)\n",
    "    maxin,indx = max((probabilities[i],i) for i in range(len(probabilities))) \n",
    "    pred.append(indx)\n",
    "    i = i+1\n",
    "    \n",
    "  res = cifar_10_evaluate(pred,test_labels)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5-ThUZGFUQU"
   },
   "outputs": [],
   "source": [
    "def cifar_10_features_div(x,N):\n",
    "  rows = len(x)\n",
    "  subimg_n = int(3*(int((32/N))**2))\n",
    "  f = []\n",
    "  k = 0\n",
    "  printProgressBar(0, rows, prefix = 'Progress:', suffix = 'Complete')\n",
    "  for item in x:\n",
    "    printProgressBar(k + 1, rows, prefix = 'Progress:', suffix = 'Complete') \n",
    "    for j in range(0,subimg_n):   \n",
    "        \n",
    "      pieces = np.mean(item[j*3072//subimg_n:(j+1)*3072//subimg_n], axis = 0, dtype=np.float64)\n",
    "      f.append(pieces)\n",
    "    k = k + 1\n",
    "  f = np.array(f, dtype=np.float64)\n",
    "  print(f.shape)\n",
    "  f = np.reshape(f, (rows,subimg_n))\n",
    "  return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "T7bBXkXxFY7t",
    "outputId": "5ce40bdf-ea88-42ac-b031-3db2f5d0155b"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-920e94425c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabel_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'airplane'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'automobile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bird'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'frog'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'horse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ship'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'truck'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cifar-10-batches-py'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cifar10_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'load_cifar10_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Main code  \n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "data_dir = 'cifar-10-batches-py'\n",
    "train_data, train_labels, test_data, test_labels = load_cifar10_data(data_dir)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Bayesian CIFAR .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
